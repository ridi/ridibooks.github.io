---
layout: career
title: "리디북스 데이터팀 소개"
subtitle: "전자책 회사의 데이터팀에서 하는 일"
description: "리디북스 데이터팀이 하는 일을 소개합니다"
header-img: "img/career-bg-14.jpg"
fb-img: "img/fb-data-team.jpg"
date: 2017-03-05
permalink: /career/data-engineer
link: https://ridi.typeform.com/to/houRxO
---

“너는 회사에서 무슨 일을 해?” 직장인들, 특히 취직한 지 얼마 안 된 분들이 종종 듣는 질문입니다. 오랜만에 만난 친구들과의 술자리에서, 또는 명절 때 친척들이 모인 자리에서, 아니면 소개팅 자리에서도 들을 수 있는 질문이지요. 이 쉬운 질문에 어쩐지 간단히 대답하기가 곤란한 사람들이 있는데, 주로 B2B 기업에 다니는 분들입니다. B2C 기업에서 하는 일들은 일반 소비자와 맞닿아 있기 때문에 대부분의 사람들이 업무의 종류와 필요성을 쉽게 상상할 수 있습니다. 하지만 B2B 기업에서 하는 일은 설명을 해 줘도 막상 듣는 사람은 그 일이 왜 필요한지, 어떤 식으로 이루어지는지 잘 그려지지 않을 수 있죠.

리디북스는 B2C 기업이지만, 그 안에도 B2B 기업 직원들의 아픔(?) 을 공감하는 사람들이 있습니다. 바로 리디북스의 데이터팀에서 일하는 데이터 엔지니어들입니다. 데이터팀이 만드는 소프트웨어는, 고객들 손 안의 스마트폰에서 실행되는 리디북스 뷰어나, 브라우저를 열면 바로 볼 수 있는 리디북스 서점처럼 고객들의 눈에 쉽게 띄지 않습니다. 그러나 데이터 엔지니어들은 고객들에게 잘 보이지 않는 서비스의 후방에서 중요한 역할을 수행하고 있습니다.

# 데이터팀이 필요한 이유

데이터팀이 하는 일을 압축해서 표현하면 다음과 같습니다.
> **각종 데이터를 수집 및 가공하여, 고객 및 사내 부서가 필요로 하는 정보를 제공한다.**

왜 이런 역할을 하는 팀이 기업에 필요할까요?

우선, **데이터에 기반한 의사결정을 돕기 위함입니다.** 기업의 업무는 수많은 의사결정으로 이루어집니다. MD들은 어떤 도서를 큐레이션할지 결정해야 하고, 마케터들은 어떤 채널로 광고를 내보내야 하는지 결정하며, CEO는 큰 틀에서의 경영 전략을 결정해야 합니다. 이러한 의사결정들은 그때그때의 감으로 이루어지는 것이 아니라, 분명한 통계와 데이터를 바탕으로 이루어지는 것이 바람직합니다. 데이터 분석가(Data Analyst)라고 불리는 사람들은 이런 의사결정자들의 요청에 의해 필요한 데이터를 추출해내고, 나아가서 이로부터 인사이트를 도출해 내는 역할을 하지요.

데이터 엔지니어들이 하는 일은, 데이터 분석가, 경영자, 마케터 등이 필요로 하는 데이터에 효율적, 효과적으로 접근할 수 있도록 돕는 일입니다. 정보를 분석하고 판단하는 것은 분석가나 경영자의 몫이지만, 엔지니어의 도움으로 그 효율을 극대화할 수 있게 됩니다. 의사결정에 필요하지만 기술적인 이유로 통계를 추출하기 어려운 경우, 그러한 기술적 문제를 해결하기도 합니다.

**데이터에 기반한 서비스를 제공**하는 것도 데이터팀의 역할입니다. 수집한 데이터를 다양한 방법으로 활용하여 고객에게 필요한 컨텐츠와 서비스를 제공하는 것입니다. 고객에게 어떤 컨텐츠를 보여줄지에 대한 의사결정 과정을 자동화한 것이라고 볼 수 있습니다. 데이터팀 업무 중에서 그나마 고객과 가장 가깝게 접할 수 있는 부분이기도 합니다.

# 데이터팀의 업무

그러면 이제 데이터팀이 어떤 일을 하는지 구체적으로 나열해 보겠습니다.

### 1. 데이터 웨어하우스 구축
데이터 분석가들은 분석 업무를 위해 MySQL 같은 관계형 데이터베이스를 조회합니다. 그러나 사용자 로그 데이터 같은 경우 전형적인 관계형 DB에 저장하기에는 용량이 너무 크고 저장 형태도 부적절합니다. 그렇기 때문에 데이터팀에서는 클러스터에 필요한 데이터를 저장해 놓고, 분석가들 또는 다른 사람들이 다양한 용도로 사용할 수 있는 인프라를 구축하고 있습니다.

### 2. 통계 제공
위에서 말한 분석 업무 중에서, 어떤 것들은 매일 또는 매달 반복적으로 조회하고 분석해야 하는 것들이 있습니다. 예를 들어 매일 발생한 신규 회원가입 수를 집계한다는지 하는 것입니다. 그런 업무는 아예 통계 페이지를 별도로 만들어 놓고, 필요한 때에 자유롭게 접근할 수 있게 하는 것이 편합니다. 데이터팀에서는 이런 목적의 페이지를 필요에 따라 개발하고 관리하는 일을 하고 있습니다. 그리고 관련 통계 집계를 위한 ETL (Extract-Transform-Load) 작업을 운영하는 일도 맡고 있습니다.

### 3. 외부 분석 도구 연동
어떤 분석 업무는 외부 솔루션을 이용하면 한결 일이 편해지는 것도 있습니다. [Google Analytics](https://www.google.com/analytics/) 는 사용자가 사이트를 어떻게 이용했는지에 대한 데이터를 수집하여 자체적으로 매우 다양한 통계를 생성해 줍니다. 페이스북 등 대부분의 광고 플랫폼은 광고를 클릭한 사용자가 사이트에서 어떤 행동을 했는지를 수집하여 광고의 효율을 분석해 주기도 합니다. 이런 분석 솔루션들은 서점 웹사이트에 자바스크립트를 약간만 수정함으로써 연동시킬 수 있습니다. 이러한 외부 분석 도구와의 연동도 데이터팀이 담당하고 있습니다.

*지금까지는 사내 부서를 대상으로 하는 업무였다면, 이제부터는 고객을 대상으로 하는 업무입니다.*

### 4. 베스트셀러

베스트셀러 집계는 고객 대상의 업무 중 가장 중요한 업무입니다. 베스트셀러에 어떻게 노출되느냐에 따라서 도서의 판매량은 크게 달라질 수 있으며, 그만큼 출판사와 작가들이 민감하게 생각하는 서비스입니다. 그렇기 때문에 베스트셀러는 까다로운 업무입니다. 매일 오전 10시까지 수십만권의 도서를 대상으로 집계를 완료해야 하는데, 오전 6시까지의 판매량을 기준으로 집계하기 때문에 주어진 시간은 많지 않습니다. 중간에 오류가 발생하여 집계가 실패하더라도 빠르게 복구하고 집계를 재개할 수 있도록 세심하게 설계하고 있습니다.

### 5. 개인 맞춤 추천
모든 사용자들에게 똑같은 컨텐츠를 보여 주는 것이 아니라, 개인의 관심사를 바탕으로 각자에게 적합한 컨텐츠를 보여 줄 수 있도록 하는 서비스입니다. 데이터 엔지니어에 지원하는 개발자들이 가장 많이 관심있어 하는 업무이기도 합니다. 사용자의 구매 내역, 별점 내역 등의 데이터를 바탕으로 다양한 알고리즘을 이용해서 도서를 추천하고 효율을 비교해 보려는 시도를 하고 있습니다.

# 데이터팀의 기술 스택

데이터팀에 지원하는 개발자들은 업무의 목적과 내용 뿐만 아니라, 어떤 기술을 사용해 보고 익힐 수 있는지도 관심있어 합니다. 데이터팀에서 사용하는 기술들을 간략하게나마 설명해 보겠습니다.

### 1. 서점 및 뷰어 로그 수집 - Javascript, Flume, Kafka
위에서 이야기했듯이, 사용자 브라우저 상에서 Google Analytics 등과의 연동을 위해 Javascript를 사용합니다.
그리고 서점이나 뷰어 API 서버의 로그를 클러스터로 수집하는 데에는 [Flume](https://flume.apache.org/) 과 [Kafka](https://kafka.apache.org/) 를 사용하고 있습니다. 이전에 Flume 을 사용해 웹서버 로그를 수집하고 모니터링하도록 설정한 것에 대해서 [포스팅](http://www.ridicorp.com/blog/2016/04/19/weblog-flume-cdh/)한 것이 있으니 참고하시면 좋습니다.

### 2. 배치 작업 운영 - Luigi, Spark
데이터팀 업무 중에서 압도적으로 많은 비중을 차지하는 것이 배치 작업입니다. 배치 작업은 하나의 데이터 집합으로부터 다른 데이터 집합을 생성하는 일입니다. [&lt;빅 데이터&gt;](https://ridibooks.com/v2/Detail?id=1170000013)에서 Nathan Marz 가 이야기한, 람다 아키텍처에서의 일괄처리 계층에 해당한다고 볼 수 있습니다. 베스트셀러, 맞춤 추천, 분석용 통계 데이터 등을 생성하는 데에 사용됩니다.

[Luigi](https://luigi.readthedocs.io/en/latest/) 는 배치 작업들간의 의존성을 정의하고 배치 작업의 실행을 관리하는 데에 사용되는 프레임워크입니다. Spotify 에서 만든 프로젝트이며, 파이썬으로 되어 있습니다.

[Spark](http://spark.apache.org/) 는 클러스터에서 분산처리를 위한 프레임워크입니다. 예전에 분산처리에 자주 사용되던 하둡 맵리듀스 프레임워크에 비해, 훨씬 빠르면서도 간단하게 코드를 표현할 수 있습니다. 스칼라, 자바, 파이썬, R 등의 언어를 사용할 수 있는데, 리디북스에서는 스칼라를 사용하여 개발하고 있습니다.

### 3. REST API 서버 및 통계 페이지 운영 - Django, MongoDB, MariaDB
리디북스는 [마이크로서비스(microservice)](https://en.wikipedia.org/wiki/Microservices) 구조를 지향합니다. 개발팀들 간의 의존성을 가능한 줄이기 위해, 각 팀은 서로 다른 서버, 서로 다른 DB백엔드, 서로 다른 코드 저장소를 사용합니다. 그리고 각 팀간에 데이터를 주고받을 때에는 REST API 를 이용합니다. 데이터팀에서 추출한 베스트셀러나 맞춤 추천 등의 결과를 서점에서 서비스하기 위해, 베스트셀러 API 와 추천 API 를 스토어팀에 오픈하여 호출하게 하고 있습니다. 람다 아키텍처에서 서빙 계층에 해당하는 부분입니다.

REST API 서버는 파이썬으로 구현되어 있으며, [Django](https://www.djangoproject.com/) 프레임워크를 사용합니다. 백엔드 저장소는 [MongoDB](https://www.mongodb.com/) 와 [MariaDB](https://mariadb.org/) 를 목적에 맞게 섞어서 사용하고 있습니다. 사업분석을 위한 통계 페이지도 같은 프레임워크를 써서 개발하고 있습니다.

### 4. 사업분석 인프라 - Impala, Zeppelin
[Impala](https://www.cloudera.com/products/open-source/apache-hadoop/impala.html) 는 하둡 클러스터에 저장되어 있는 데이터에 대해 손쉽게 ad-hoc 쿼리를 실행할 수 있게 만든 시스템입니다. 저장된 데이터의 경로와 파일 포맷을 마치 관계형 DB의 테이블처럼 추상화합니다. 이 상태에서 SQL과 거의 동일한 문법의 쿼리를 실행하여 결과를 받아올 수 있습니다. Hive 도 이와 비슷한 시스템이지만, 쿼리 지연시간이 매우 느리다는 단점이 있습니다. 반면 Impala 는 분석 업무를 하는 사람들을 위해 만들어졌기 때문에 훨씬 빠릅니다.

[Zeppelin](https://zeppelin.apache.org/) 은 요즘 말하는 노트북(notebook) 인터페이스 입니다. 웹페이지 내에서 쿼리나 코드를 작성하면 인터프리터가 바로 실행하여 결과 데이터를 보여줍니다. 결과는 표로 나타낼 수도 있고, 그래프로 표시할 수도 있습니다. Spark 인터프리터가 있어서 하둡 시스템과의 연동이 강력합니다.

<hr>

# 데이터 엔지니어를 찾습니다

‘빅 데이터’ 라는 말이 화제가 되더니 이제 어느덧 일상적인 용어가 되었습니다. 그러면서 데이터 분석가, 데이터 사이언티스트, 데이터 엔지니어 등의 직업에 관심을 가지는 사람이 많아졌습니다. 리디북스에도 데이터 엔지니어 포지션에 지원하는 사람들이 많고, 어떻게 하면 데이터 엔지니어로 일할 수 있는지 문의하시는 분들도 많습니다. 특히 대학을 갓 졸업한 신입 개발자 분들, 또는 다른 분야에서 일하시다가 이쪽 분야에 새로 눈을 돌리신 분들이 많은 것 같습니다.

우선 말씀드릴 것은, “데이터 엔지니어”는 “데이터 분석가”와는 확실히 다르다는 것입니다. 수많은 데이터 속에서 아무도 발견하지 못했던 어떤 한줄기 인사이트를 멋지게 찾아내는 역할을 기대하며 찾아오시는 분들이 많은데, 그것은 데이터 엔지니어라기보다는 데이터 분석가의 역할입니다. (리디북스는 데이터 분석가 포지션의 채용도 하고 있습니다.)

**데이터 엔지니어는 보다 “엔지니어”, 즉 소프트웨어 개발자에 가깝습니다.** 소프트웨어를 작성하고 다양한 기술적 문제를 해결하는 것이 주 업무입니다. 그렇기 때문에 데이터 엔지니어에게 요구되는 역량은 다른 개발자에게 요구되는 역량과 크게 다르지 않습니다. 다양한 상황에서 최적의 솔루션을 찾을 수 있는 문제 해결 능력, 변화하는 기술시장에서 새로운 지식을 빠르게 습득할 수 있는 능력, 다른 직원들과의 협업에 필수적인 의사소통 능력 등입니다. 머신 러닝에 대한 깊은 지식이나 하둡 에코시스템을 오랫동안 다뤄본 경험이 있으면 더욱 좋겠지만, 그런 것들은 필수가 아닙니다. 엔지니어로서의 기본 역량이 뛰어난 사람을 가장 선호합니다.

위에서 말한 역량들을 모두 훌륭하게 갖춘 개발자가 되는 것은 쉽지는 않습니다. 저와 지금의 데이터팀 멤버들도 필요한 역량을 갖추기 위해 매일 노력하고 있고, 그 과정에서 성장하고 있습니다. **개발자로서, 빠른 속도로 발전하는 회사와 함께 성장하는 것은 더할 나위 없이 좋은 기회입니다. 이 좋은 기회를 함께 누리실 분을 데이터팀에서는 찾고 있습니다.**
